{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Problem2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3810jvsc74a57bd0491c2f80683c629c20ebc0840e9e96fe97634a702a1ec3316562a660dd2c9b99",
      "display_name": "Python 3.8.10 64-bit ('.venv': venv)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    },
    "metadata": {
      "interpreter": {
        "hash": "cd2e177a4d5c6f47cf7f164e8ded48b6f3ffc0825f81ee00871d9807b7ac9996"
      }
    }
  },
  "cells": [
    {
      "source": [
        "## Model compression\n",
        "\n",
        "This file will **compress the model** generated by the transfer learning to a TF Lite model.\n",
        "\n",
        "To run this code you need to have a model ready and the test dataset folder set, you can download it here: https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-test-set.zip\n",
        "\n",
        "you then need to put it in the `Dataset` folder to have this hierarchy:\n",
        "\n",
        "* Dataset\n",
        "    - Test\n",
        "        - paper\n",
        "        - rock\n",
        "        - scissors"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujYsE_FkX0Xb"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import time\n",
        "import PIL.Image as Image"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "source": [
        "If you need, you can change the path to your `TFModel`, `TFLiteModel` and `Dataset` folder here."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pkz21xyKEXbs"
      },
      "source": [
        "path_to_model_folder = \"saved_models/TFModel/\"\n",
        "path_to_tf_model_folder = \"saved_models/TFLiteModel/\"\n",
        "dataset_test = \"Dataset/Test\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "source": [
        "This cell will load your saved model and convert it to a TF lite model.\n",
        "\n",
        "It then saves the TF lite model to the same folder as the non compressed model."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2eQrCBDYBT-"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(path_to_model_folder + \"RPS_Fine_Tuned_Model\") # path to the SavedModel directory\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "\n",
        "# Save the model\n",
        "with open(path_to_tf_model_folder + \"RPS_Fine_Tuned_Model.tflite\", 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "source": [
        "## Testing the TF lite model\n",
        "\n",
        "The following code will test the compressed model to see its accuracy."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "TF lite models only accept **one image at the time**, we therefore have to load all our images manually.\n",
        "\n",
        "Also, our dataset is compose of png images that have alpha channel, but our **model do not accept images that have an alpha channel**.\n",
        "\n",
        "This function **load all the images** in the dataset test folder, **remove the alpha channel** and **put it in an array**."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMAGE_SHAPE = (224, 224)\n",
        "\n",
        "def load_dataset():\n",
        "    X_test = []\n",
        "    y_test = []\n",
        "\n",
        "    for classes in os.listdir(dataset_test):\n",
        "        if classes == \".gitkeep\":\n",
        "            continue\n",
        "        classes_path = os.path.join(dataset_test, classes)\n",
        "        for image_name in os.listdir(classes_path):\n",
        "            img = Image.open(os.path.join(classes_path, image_name)).resize(IMAGE_SHAPE)\n",
        "            alpha = img.convert('RGBA').split()[-1]\n",
        "            bg = Image.new(\"RGB\", img.size, (255, 255, 255))\n",
        "            bg.paste(img, mask=alpha)\n",
        "            X_test.append(np.array(bg, dtype=np.float32)/255.0)\n",
        "            y_test.append(classes)\n",
        "    return X_test, y_test"
      ]
    },
    {
      "source": [
        "This cell creates an interpreter with the TF lite model and it gives us the **inputs and outputs** of the model."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bTmVaZ7k8r3"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "input_shape = input_details[0]['shape']\n",
        "\n",
        "X_test, y_test = load_dataset()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "source": [
        "The model will now predict the classes for all images in our test set.\n",
        "\n",
        "This cell also keeps track of the time needed for each classification."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "predicted_result = []\n",
        "classifing_speed = []\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "    start_time = time.time()\n",
        "    test = np.array(X_test[i][np.newaxis, ...])\n",
        "    interpreter.set_tensor(input_details[0]['index'], test)\n",
        "    interpreter.invoke()\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "    classifing_speed.append(time.time() - start_time)\n",
        "    predicted_result.append(np.argmax(output_data[0], axis = -1))"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RGF93Jv5lcH",
        "outputId": "73ef5af7-7705-424f-9bc1-664e089c537f"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average time to classify an image is:  0.033375687496636504\n"
          ]
        }
      ],
      "source": [
        "average_time_per_image = sum(classifing_speed) / len(predicted_result)\n",
        "print(\"Average time to classify an image is: \", average_time_per_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of TFlite model is:  0.8225806451612904\n"
          ]
        }
      ],
      "source": [
        "accuracy = 0.0\n",
        "\n",
        "for i in range(len(predicted_result)):\n",
        "    if ({0:'paper', 1:'rock', 2:'scissors'}[predicted_result[i]] == y_test[i]):\n",
        "        accuracy += 1\n",
        "\n",
        "accuracy = accuracy / len(predicted_result)\n",
        "print(\"Accuracy of TFlite model is: \", accuracy)"
      ]
    },
    {
      "source": [
        "## Result\n",
        "\n",
        "The TF lite mode takes 0.03 second to classify an image which is really good.\n",
        "\n",
        "It has an accuracy of 0.82, it lost 0.1 of accuracy with the compression but it is usable."
      ],
      "cell_type": "markdown",
      "metadata": {}
    }
  ]
}